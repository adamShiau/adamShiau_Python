import os
import requests
from bs4 import BeautifulSoup
import pdfkit
from urllib.parse import urljoin
from pypdf import PdfReader, PdfWriter

# ==============================
# ğŸ§© æ§åˆ¶é¸é …
# ==============================
GENERATE_SINGLE_PDFS = True    # æ˜¯å¦ç”Ÿæˆæ¯ä¸€åˆ†é¡ç¨ç«‹ PDF
MERGE_ALL_IN_ONE     = True    # æ˜¯å¦å°‡æ‰€æœ‰åˆ†é¡åˆä½µæˆä¸€ä»½
DELETE_TEMP_PDFS     = True    # åˆä½µå¾Œæ˜¯å¦åˆªé™¤ä¸­é–“æª”

BOOKMARK_ROOT_NAME = "Data Overview"
SAVE_PATH = "manual/MIP Protocol"
SAVE_NAME = "Data_Overview.pdf"

# ==============================
# ğŸ“‚ è¼¸å‡ºè³‡æ–™å¤¾
# ==============================
# OUTPUT_DIR = os.path.join(os.getcwd(), SAVE_PATH, BOOKMARK_ROOT_NAME)
OUTPUT_DIR = os.path.join(os.getcwd(), SAVE_PATH)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ==============================
# 1ï¸âƒ£ Commands å„åˆ†é¡å…¥å£
# ==============================
COMMANDS_SECTIONS = {
    "Data Overview": "https://s3.amazonaws.com/files.microstrain.com/CV7_INS_Manual/dcp_content/introduction/Data%20Overview.htm",
    "MIP Continuation Packets": "https://s3.amazonaws.com/files.microstrain.com/CV7_INS_Manual/dcp_content/introduction/MIP%20Continuation%20Packets.htm",
    "Shared Data Descriptors": "https://s3.amazonaws.com/files.microstrain.com/CV7_INS_Manual/dcp_content/introduction/Shared%20Data%20Descriptors.htm"
}

# ==============================
# 2ï¸âƒ£ æ‰‹å‹•è£œå……éºæ¼é 
# ==============================
EXTRA_PAGES = {

}

# ==============================
# 3ï¸âƒ£ wkhtmltopdf è¨­å®š
# ==============================
config = pdfkit.configuration(
    wkhtmltopdf=r"C:\Program Files\wkhtmltopdf\bin\wkhtmltopdf.exe"
)
options = {
    'enable-javascript': '',
    'javascript-delay': 4000,
    'no-stop-slow-scripts': '',
    'enable-local-file-access': '',
    'encoding': "UTF-8"
}

# ==============================
# 4ï¸âƒ£ æŠ“å–å­é é¢
# ==============================
def collect_pages(entry_url):
    """æ”¶é›†å­é é¢ï¼ˆå« 0x / é 0x é …ç›®ï¼‰"""
    ordered_urls = [entry_url]
    try:
        resp = requests.get(entry_url)
        resp.raise_for_status()
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•é–‹å•Ÿ {entry_url}: {e}")
        return ordered_urls

    soup = BeautifulSoup(resp.text, "html.parser")

    for a in soup.select("a[href]"):
        href = a["href"].strip()
        full_url = urljoin(entry_url, href)

        if (
            href.startswith("#")
            or "Home" in href
            or "Product" in href
            or not href.lower().endswith(".htm")
            or "CV7_INS_Manual" not in full_url
        ):
            continue

        if full_url not in ordered_urls:
            ordered_urls.append(full_url)

    return ordered_urls


# ==============================
# 5ï¸âƒ£ é€ä¸€ä¸‹è¼‰ PDF
# ==============================
generated_pdfs = []

if GENERATE_SINGLE_PDFS:
    for name, url in COMMANDS_SECTIONS.items():
        print(f"\nğŸ“¥ æ”¶é›† {name} ...")
        pages = collect_pages(url)

        if name in EXTRA_PAGES:
            print(f"â• åŠ å…¥ {len(EXTRA_PAGES[name])} å€‹æ‰‹å‹•è£œé ")
            pages.extend(EXTRA_PAGES[name])

        print(f"ğŸ“‘ å…±æ‰¾åˆ° {len(pages)} å€‹é é¢")

        output_file = os.path.join(OUTPUT_DIR, f"MIP_API_Commands_{name.replace(' ', '_').replace('(', '').replace(')', '')}.pdf")
        print(f"ğŸ“„ ç”¢ç”Ÿ PDF: {output_file}")
        pdfkit.from_url(pages, output_file, configuration=config, options=options)
        generated_pdfs.append(output_file)

# ==============================
# 6ï¸âƒ£ åˆä½µæˆå–®ä¸€ PDF
# ==============================
if MERGE_ALL_IN_ONE and generated_pdfs:
    print("\nğŸ“š é–‹å§‹åˆä½µæ‰€æœ‰åˆ†é¡ PDF ...")

    writer = PdfWriter()
    outline_root = writer.add_outline_item(BOOKMARK_ROOT_NAME, 0)
    current_page = 0

    for pdf_path in generated_pdfs:
        print(f"â¡ï¸ åˆä½µ {pdf_path} ...")
        reader = PdfReader(pdf_path)

        section_title = os.path.basename(pdf_path).replace("MIP_API_Commands_", "").replace(".pdf", "")
        section_outline = writer.add_outline_item(section_title, current_page, parent=outline_root)

        # åŠ å…¥é é¢
        for page in reader.pages:
            writer.add_page(page)

        # åŒ¯å…¥æ›¸ç±¤
        try:
            def import_outline(items, parent=None, base_page=current_page):
                for it in items:
                    if isinstance(it, list):
                        import_outline(it, parent, base_page)
                        continue

                    title = None
                    if isinstance(it, dict):
                        title = it.get("Title") or it.get("/Title")
                        page_idx = it.get("Page") or it.get("/Page") or 0
                    elif hasattr(it, "title"):
                        title = getattr(it, "title", None)
                        try:
                            page_idx = reader.get_destination_page_number(it)
                        except Exception:
                            page_idx = 0
                    elif hasattr(it, "get"):
                        title = it.get("/Title")
                        page_idx = it.get("/Page", 0)
                    else:
                        title = str(it)
                        page_idx = 0

                    if not title or title.strip() == "":
                        title = "Untitled"

                    try:
                        writer.add_outline_item(title, base_page + int(page_idx), parent=parent)
                    except Exception:
                        writer.add_outline_item(title, base_page, parent=parent)

            if reader.outline:
                import_outline(reader.outline, section_outline, current_page)
        except Exception as e:
            print(f"âš ï¸ åŒ¯å…¥æ›¸ç±¤æ™‚ç™¼ç”Ÿå•é¡Œï¼š{e}")

        current_page += len(reader.pages)

    final_pdf = os.path.join(OUTPUT_DIR, SAVE_NAME)
    with open(final_pdf, "wb") as f_out:
        writer.write(f_out)

    print(f"ğŸ¯ å·²æˆåŠŸç”¢ç”Ÿåˆä½µå¾Œçš„ PDFï¼š{final_pdf}")

    # æ¸…ç†ä¸­é–“æª”
    if DELETE_TEMP_PDFS and GENERATE_SINGLE_PDFS:
        for f in generated_pdfs:
            try:
                os.remove(f)
                print(f"ğŸ§¹ å·²åˆªé™¤æš«å­˜æª”ï¼š{f}")
            except Exception:
                pass
