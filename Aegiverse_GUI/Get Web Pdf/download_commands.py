import requests
from bs4 import BeautifulSoup
import pdfkit
from urllib.parse import urljoin

# --- Commands å„åˆ†é¡å…¥å£ ---
COMMANDS_SECTIONS = {
    "3DM (0x0C)": "https://s3.us-east-1.amazonaws.com/files.microstrain.com/CV7_GNSS_INS_Online/external_content/dcp/Commands/0x0c/0x0c_links.htm",
    "Aiding (0x13)": "https://s3.us-east-1.amazonaws.com/files.microstrain.com/CV7_GNSS_INS_Online/external_content/dcp/Commands/0x13/0x13_links.htm",
    "Base (0x01)": "https://s3.us-east-1.amazonaws.com/files.microstrain.com/CV7_GNSS_INS_Online/external_content/dcp/Commands/0x01/0x01_links.htm",
    "Filter (0x0D)": "https://s3.us-east-1.amazonaws.com/files.microstrain.com/CV7_GNSS_INS_Online/external_content/dcp/Commands/0x0d/0x0d_links.htm",
    "GNSS (0x0E)": "https://s3.us-east-1.amazonaws.com/files.microstrain.com/CV7_GNSS_INS_Online/external_content/dcp/Commands/0x0e/0x0e_links.htm",
    "System (0x7F)": "https://s3.us-east-1.amazonaws.com/files.microstrain.com/CV7_GNSS_INS_Online/external_content/dcp/Commands/0x7f/0x7f_links.htm"
}

# wkhtmltopdf è·¯å¾‘ï¼ˆè«‹æ”¹æˆä½ çš„å¯¦éš›å®‰è£ä½ç½®ï¼‰
config = pdfkit.configuration(
    wkhtmltopdf=r"C:\Program Files\wkhtmltopdf\bin\wkhtmltopdf.exe"
)

# PDF è½‰æ›é¸é …
options = {
    'enable-javascript': '',
    'javascript-delay': 4000,   # å¤šç­‰ä¸€é»ï¼Œé¿å…ç©ºç™½
    'no-stop-slow-scripts': '',
    'enable-local-file-access': '',
    'encoding': "UTF-8"
}

def collect_pages(entry_url):
    """æ”¶é›†æŸä¸€åˆ†é¡ï¼ˆä¾‹å¦‚ 3DMï¼‰çš„æ‰€æœ‰å­é """
    ordered_urls = [entry_url]
    resp = requests.get(entry_url)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    for a in soup.select("a"):
        href = a.get("href")
        text = a.text.strip()
        if href and ("0x" in text or "Uncertainty" in text or "Bias" in text):
            full_url = urljoin(entry_url, href)
            ordered_urls.append(full_url)

    return ordered_urls

# --- é€ä¸€ä¸‹è¼‰æ¯å€‹åˆ†é¡ ---
for name, url in COMMANDS_SECTIONS.items():
    print(f"ğŸ“¥ æ”¶é›† {name} ...")
    pages = collect_pages(url)
    print(f"  -> æ‰¾åˆ° {len(pages)} å€‹é é¢")

    output_file = f"MIP_API_Commands_{name.replace(' ', '_').replace('(', '').replace(')', '').replace('/', '_')}.pdf"
    print(f"ğŸ“„ ç”¢ç”Ÿ PDF: {output_file}")

    pdfkit.from_url(pages, output_file, configuration=config, options=options)

print("ğŸ‰ Commands åˆ†é¡ PDF å…¨éƒ¨ç”Ÿæˆå®Œæˆï¼")
